{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0ef4e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.impute import SimpleImputer    \n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor    \n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV, KFold    \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4acbc7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "original = pd.read_csv('archive/CrabAgePrediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3117226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74051 entries, 0 to 74050\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              74051 non-null  int64  \n",
      " 1   Sex             74051 non-null  object \n",
      " 2   Length          74051 non-null  float64\n",
      " 3   Diameter        74051 non-null  float64\n",
      " 4   Height          74051 non-null  float64\n",
      " 5   Weight          74051 non-null  float64\n",
      " 6   Shucked Weight  74051 non-null  float64\n",
      " 7   Viscera Weight  74051 non-null  float64\n",
      " 8   Shell Weight    74051 non-null  float64\n",
      " 9   Age             74051 non-null  int64  \n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "58352f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3893 entries, 0 to 3892\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             3893 non-null   object \n",
      " 1   Length          3893 non-null   float64\n",
      " 2   Diameter        3893 non-null   float64\n",
      " 3   Height          3893 non-null   float64\n",
      " 4   Weight          3893 non-null   float64\n",
      " 5   Shucked Weight  3893 non-null   float64\n",
      " 6   Viscera Weight  3893 non-null   float64\n",
      " 7   Shell Weight    3893 non-null   float64\n",
      " 8   Age             3893 non-null   int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 273.9+ KB\n"
     ]
    }
   ],
   "source": [
    "original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b30eefdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77944, 9)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([data.drop('id', axis=1), original])\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1fdd4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77944 entries, 0 to 3892\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             77944 non-null  object \n",
      " 1   Length          77944 non-null  float64\n",
      " 2   Diameter        77944 non-null  float64\n",
      " 3   Height          77944 non-null  float64\n",
      " 4   Weight          77944 non-null  float64\n",
      " 5   Shucked Weight  77944 non-null  float64\n",
      " 6   Viscera Weight  77944 non-null  float64\n",
      " 7   Shell Weight    77944 non-null  float64\n",
      " 8   Age             77944 non-null  int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c7db3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7  # a small constant\n",
    "\n",
    "def engineer_features(data):\n",
    "    data['shell_to_total_weight_ratio'] = data['Shell Weight'] / (data['Weight'] + epsilon)\n",
    "    data['shucked_to_total_weight_ratio'] = data['Shucked Weight'] / (data['Weight'] + epsilon)    \n",
    "    \n",
    "    # Adding interaction terms\n",
    "    data['interaction_1'] = data['Shell Weight'] * data['Weight']\n",
    "    data['interaction_2'] = data['Shucked Weight'] * data['Weight']\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0942addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer features\n",
    "new_data = engineer_features(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "54525915",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "550dbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_data.columns:\n",
    "    if new_data[col].dtype == np.float64:\n",
    "        new_data[col] = new_data[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "07972b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 22878 to 5289\n",
      "Data columns (total 13 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Sex                            100 non-null    object \n",
      " 1   Length                         100 non-null    float32\n",
      " 2   Diameter                       100 non-null    float32\n",
      " 3   Height                         100 non-null    float32\n",
      " 4   Weight                         100 non-null    float32\n",
      " 5   Shucked Weight                 100 non-null    float32\n",
      " 6   Viscera Weight                 100 non-null    float32\n",
      " 7   Shell Weight                   100 non-null    float32\n",
      " 8   Age                            100 non-null    int64  \n",
      " 9   shell_to_total_weight_ratio    100 non-null    float32\n",
      " 10  shucked_to_total_weight_ratio  100 non-null    float32\n",
      " 11  interaction_1                  100 non-null    float32\n",
      " 12  interaction_2                  100 non-null    float32\n",
      "dtypes: float32(11), int64(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba539b",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a71ae603",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(columns=['Age'])\n",
    "y = new_data['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "726f64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical and categorical columns\n",
    "num_columns = list(X.select_dtypes(exclude='object').columns)\n",
    "cat_columns = list(X.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aaa5bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "43581a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "                    transformers=[('num', PowerTransformer(method='yeo-johnson'), num_columns),\n",
    "                                  ('cat', OneHotEncoder(handle_unknown=\"ignore\"), cat_columns)] \n",
    "                                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e73d433c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Length', 'Diameter', 'Height', 'Weight', 'Shucked Weight',\n",
       "       'Viscera Weight', 'Shell Weight', 'shell_to_total_weight_ratio',\n",
       "       'shucked_to_total_weight_ratio', 'interaction_1', 'interaction_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0f85c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_models = [\n",
    "#         ('xgb', XGBRegressor(random_state=42, tree_method='gpu_hist')),\n",
    "#         ('rf', RandomForestRegressor(random_state=42)),\n",
    "#         ('lgb', lgb.LGBMRegressor(random_state=42, device='gpu')),\n",
    "#         ('cat', CatBoostRegressor(random_state=42, silent=True, task_type='GPU'))\n",
    "#     ]\n",
    "\n",
    "\n",
    "# feature_importances = {}\n",
    "\n",
    "# for model_name, model in base_models:\n",
    "#     pipeline = Pipeline(steps=[ \n",
    "#                                 ('Preprocessor', preprocessor),\n",
    "#                                 ('Scaler', StandardScaler()),\n",
    "#                                 ('Regressor', model)\n",
    "#                               ])\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     if hasattr(model, \"feature_importances_\"):\n",
    "#         feature_importances[model_name] = model.feature_importances_\n",
    "#     elif hasattr(model, \"coef_\"):\n",
    "#         feature_importances[model_name] = model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "da6bbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract transformed feature names\n",
    "# cat_feature_names = pipeline.named_steps['Preprocessor'].named_transformers_['cat'].get_feature_names_out(input_features=cat_columns)\n",
    "\n",
    "# # Combine numerical and categorical feature names\n",
    "# # Note: cat_feature_names comes first to align with how the model sees the features\n",
    "# feature_names = cat_feature_names.tolist() + num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "59fc4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your feature names are available in feature_names variable\n",
    "# importance_df = pd.DataFrame(feature_importances, index=feature_names)\n",
    "\n",
    "# # Take mean of feature importances across models\n",
    "# importance_df['mean_importance'] = importance_df.mean(axis=1)\n",
    "\n",
    "# # Select top n features\n",
    "# n = 10  # or whatever number of features you want to keep\n",
    "# top_features = importance_df.nlargest(n, 'mean_importance').index\n",
    "\n",
    "# # # Filter your data to only include these top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "38a2f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features = top_features.to_list()\n",
    "# if 'Sex_F' in top_features:\n",
    "#     top_features.remove('Sex_F')\n",
    "# if 'Sex_I' in top_features:\n",
    "#     top_features.remove('Sex_I')\n",
    "# if 'Sex_M' in top_features:\n",
    "#     top_features.remove('Sex_M')    \n",
    "# if 'Sex' not in top_features:\n",
    "#     top_features.append('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c8badba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train[top_features]\n",
    "# X_test = X_test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c0d634f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b876a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL DATTA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('xgb', XGBRegressor(random_state=42, tree_method='gpu_hist')),\n",
    "#     ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('lgb', lgb.LGBMRegressor(random_state=42, device='gpu')),\n",
    "    ('cat', CatBoostRegressor(random_state=42, silent=True, task_type='GPU'))\n",
    "]\n",
    "\n",
    "#     # Define meta learner model\n",
    "final_model = LinearRegression()\n",
    "\n",
    "# Define the stacking ensemble\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=final_model, cv=5)\n",
    "\n",
    "\n",
    "feature_engineering = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "\n",
    "\n",
    "# Define the feature selection method\n",
    "feature_selection = RFE(RandomForestRegressor(n_estimators=100), n_features_to_select=7)\n",
    "\n",
    "# Preparing the pipeline architecture\n",
    "pipeline = Pipeline(steps=[ \n",
    "                            ('Preprocessor', preprocessor),\n",
    "                            ('pca', PCA(n_components = 10)),\n",
    "#                             ('Scaler', StandardScaler()),\n",
    "                            ('Regressor', stacking_regressor)\n",
    "                          ]\n",
    "                       )\n",
    "\n",
    "# cross validation\n",
    "kFold = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "# Define the hyperparameters for each model in the ensemble\n",
    "params = { \n",
    "'Regressor__xgb__n_estimators': [500, 1000],\n",
    "'Regressor__xgb__max_depth': [15],\n",
    "'Regressor__xgb__learning_rate': [0.01],\n",
    "'Regressor__xgb__subsample': [0.8],\n",
    "'Regressor__xgb__tree_method': ['gpu_hist'],\n",
    "# 'Regressor__rf__n_estimators': [ 600, 1000],\n",
    "# 'Regressor__rf__max_depth': [20],\n",
    "# 'Regressor__rf__min_samples_split': [5],\n",
    "# 'Regressor__rf__min_samples_leaf': [5],\n",
    "'Regressor__lgb__n_estimators': [300, 600, 900],\n",
    "'Regressor__lgb__max_depth': [6],\n",
    "'Regressor__lgb__learning_rate': [0.01],\n",
    "'Regressor__lgb__subsample': [0.6],\n",
    "'Regressor__lgb__device': ['gpu'],\n",
    "'Regressor__cat__iterations': [500, 1000],\n",
    "'Regressor__cat__depth': [6],\n",
    "'Regressor__cat__learning_rate': [0.05],\n",
    "'Regressor__cat__task_type': ['GPU']\n",
    "}\n",
    "\n",
    "# Update hyperparameters range\n",
    "params_xgb = {\n",
    "               'Regressor__max_depth': [6, 8, 10, 12],\n",
    "               'Regressor__learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "               'Regressor__subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "               'Regressor__colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "               'Regressor__n_estimators': [100, 200, 500, 1000],\n",
    "               'Regressor__tree_method': ['gpu_hist'],\n",
    "             }\n",
    "# Initialize hyper parameter tuning using RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=pipeline,\n",
    "                                   param_distributions=params,\n",
    "                                   scoring='neg_mean_absolute_error',\n",
    "                                   n_iter=50,  # increase this value as needed\n",
    "                                   cv=kFold,\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=3,\n",
    "                                   random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "cv_score = random_search.best_score_\n",
    "test_score = random_search.score(X_test, y_test) \n",
    "\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5464f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot learning curves\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# Generate the plot\n",
    "plot_learning_curve(random_search.best_estimator_, \"Learning curve\", X, y, cv=KFold(n_splits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_params_\n",
    "random_search.best_params_\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79a6e7",
   "metadata": {},
   "source": [
    "Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_search.predict(X_test)\n",
    "# y_pred = grid_search.predict(X_test)\n",
    "errors = abs(y_test - y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a59a1",
   "metadata": {},
   "source": [
    "This can give you an idea about the distribution of errors (are they normal, skewed, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4523168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(errors, bins=30)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.title('Histogram of prediction errors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8851d6a6",
   "metadata": {},
   "source": [
    "Identifying instances with high error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Error': errors})\n",
    "error_df.sort_values('Error', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe051dc4",
   "metadata": {},
   "source": [
    "Analyzing residuals vs. predicted plot.\n",
    "    - A residuals vs. predicted plot can provide insight into whether my model \n",
    "      is systematically over or underpredicting at certain levels of the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de972c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred, y_test - y_pred)\n",
    "plt.xlabel('Predicted Age')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Residuals vs Predicted Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a88a5",
   "metadata": {},
   "source": [
    "Errors across different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340d8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = X_test.copy()\n",
    "error_df['Error'] = errors\n",
    "error_df.groupby('Sex')['Error'].mean().plot(kind='bar')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Error across different genders')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f98ddc9",
   "metadata": {},
   "source": [
    "Generating Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ebb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "new_test = engineer_features(test)\n",
    "\n",
    "ids = test.id\n",
    "# y_pred = grid_search.predict(test)\n",
    "y_pred = random_search.predict(new_test)\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':ids, 'Age': y_pred})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa631f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c069e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission11.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96970da1",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8bb74ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 2.4271 - val_loss: 1.5332\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.6458 - val_loss: 1.5468\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.6008 - val_loss: 1.5583\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.5807 - val_loss: 1.4805\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.5564 - val_loss: 1.4379\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.5481 - val_loss: 1.4503\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.5123 - val_loss: 1.4402\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4967 - val_loss: 1.4194\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.5166 - val_loss: 1.4002\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.5066 - val_loss: 1.4124\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4854 - val_loss: 1.4320\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4957 - val_loss: 1.4345\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4796 - val_loss: 1.4253\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4842 - val_loss: 1.3854\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4822 - val_loss: 1.3750\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4823 - val_loss: 1.3638\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4760 - val_loss: 1.3697\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4808 - val_loss: 1.4455\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4827 - val_loss: 1.4038\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4751 - val_loss: 1.4007\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4712 - val_loss: 1.3714\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4602 - val_loss: 1.3925\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4709 - val_loss: 1.4226\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4616 - val_loss: 1.3692\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4727 - val_loss: 1.3614\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4622 - val_loss: 1.3870\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4551 - val_loss: 1.3717\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4801 - val_loss: 1.3605\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4599 - val_loss: 1.3705\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4595 - val_loss: 1.4737\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4551 - val_loss: 1.3693\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4605 - val_loss: 1.3898\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4660 - val_loss: 1.4280\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4513 - val_loss: 1.4521\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.4545 - val_loss: 1.3633\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4556 - val_loss: 1.3647\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4479 - val_loss: 1.3810\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4540 - val_loss: 1.3908\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4575 - val_loss: 1.4055\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4456 - val_loss: 1.3686\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4576 - val_loss: 1.4093\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.4506 - val_loss: 1.3684\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4440 - val_loss: 1.3541\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4625 - val_loss: 1.3828\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4594 - val_loss: 1.3953\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4606 - val_loss: 1.3841\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4534 - val_loss: 1.3558\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4547 - val_loss: 1.3796\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4470 - val_loss: 1.4245\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4461 - val_loss: 1.3596\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4462 - val_loss: 1.3608\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4529 - val_loss: 1.3771\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4504 - val_loss: 1.3538\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4471 - val_loss: 1.3696\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.4471 - val_loss: 1.3660\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4487 - val_loss: 1.3655\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4445 - val_loss: 1.3653\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4466 - val_loss: 1.4686\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4640 - val_loss: 1.3586\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4414 - val_loss: 1.3815\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4378 - val_loss: 1.3777\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4374 - val_loss: 1.4989\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4475 - val_loss: 1.3654\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4392 - val_loss: 1.4038\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4391 - val_loss: 1.4069\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4411 - val_loss: 1.3661\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4407 - val_loss: 1.3501\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.4293 - val_loss: 1.4129\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4432 - val_loss: 1.3575\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.4317 - val_loss: 1.3684\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.4357 - val_loss: 1.3559\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.4372 - val_loss: 1.3595\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4433 - val_loss: 1.3558\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4477 - val_loss: 1.3943\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4281 - val_loss: 1.3949\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4306 - val_loss: 1.3845\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4461 - val_loss: 1.3626\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4425 - val_loss: 1.3747\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4371 - val_loss: 1.4105\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4326 - val_loss: 1.3960\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4291 - val_loss: 1.3558\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4299 - val_loss: 1.3671\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4281 - val_loss: 1.3865\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4333 - val_loss: 1.4568\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4331 - val_loss: 1.3715\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4292 - val_loss: 1.4074\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4344 - val_loss: 1.3997\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4320 - val_loss: 1.3681\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4285 - val_loss: 1.3473\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4218 - val_loss: 1.3587\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4443 - val_loss: 1.3777\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4276 - val_loss: 1.4045\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4225 - val_loss: 1.3614\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4448 - val_loss: 1.4634\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4332 - val_loss: 1.3820\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4359 - val_loss: 1.3563\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4254 - val_loss: 1.3978\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4265 - val_loss: 1.3621\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4308 - val_loss: 1.3677\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4259 - val_loss: 1.3731\n",
      "63/63 [==============================] - 0s 777us/step - loss: 1.3731\n",
      "Test loss: 1.3730838298797607\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# Prepare the transformers for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), [1, 2, 3, 4, 5, 6]),\n",
    "        ('cat', OneHotEncoder(), [0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply transformations to X\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_absolute_error')\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5d9f2001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543/1543 [==============================] - 1s 636us/step\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "X = engineer_features(test)\n",
    "X = preprocessor.transform(X)\n",
    "\n",
    "ids = test.id\n",
    "y_pred = model.predict(X)\n",
    "# y_pred = random_search.predict(new_test)\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b0019d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':ids, 'Age': y_pred.flatten()})\n",
    "submission.to_csv('submission10_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c74b6db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74051</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74052</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74053</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74054</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74055</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49363</th>\n",
       "      <td>123414</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49364</th>\n",
       "      <td>123415</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49365</th>\n",
       "      <td>123416</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49366</th>\n",
       "      <td>123417</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49367</th>\n",
       "      <td>123418</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49368 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   Age\n",
       "0       74051   7.0\n",
       "1       74052   8.0\n",
       "2       74053  10.0\n",
       "3       74054   9.0\n",
       "4       74055   7.0\n",
       "...       ...   ...\n",
       "49363  123414  10.0\n",
       "49364  123415   7.0\n",
       "49365  123416  14.0\n",
       "49366  123417  10.0\n",
       "49367  123418  12.0\n",
       "\n",
       "[49368 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70834c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
